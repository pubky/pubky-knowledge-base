{"App-Architectures/1.-Introduction":{"title":"1. Introduction","links":["Pubky-Core/Introduction","Pubky-Core/Data-Stores","App-Architectures/2.-Client---Homeserver","App-Architectures/4.-Custom-Backend","App-Architectures/3.-Global-Aggregators"],"tags":[],"content":"Leveraging the Pubky Core protocol as the foundational layer, we can envision a diverse array of applications with distinct functionalities. While each app can implement its own unique design patterns and user interfaces, they all share a common underlying architecture: interacting with the distributed data stores, colloquially referred to as home servers, through standardized read and write operations.\nThe Pubky Core protocol enables a decentralized approach to data management, facilitating seamless communication between clients and their respective data stores. This architecture promotes data sovereignty and enhances system resilience.\nBelow, we present several high-level designs that showcase the versatility of this architecture, from simple client (browser) apps that interact directly with one or several homeservers to more complex applications with custom aggregators and backends capable of powerful inference:\n\nClient-Homeserver\nCustom backend\nGlobal aggregators\n"},"App-Architectures/2.-Client---Homeserver":{"title":"2. Client - Homeserver","links":[],"tags":[],"content":"\nIn this architecture, we implement a direct communication model between the client application and the home server. This approach minimizes latency and reduces system complexity by establishing a direct data flow pathway.\nThis design pattern is particularly well-suited for applications with straightforward functionality, especially those that don’t require real-time interaction or data normalization. This architectural approach demonstrates optimal performance in use cases characterized by intermittent data operations, where asynchronous read/write cycles are adequate for maintaining data consistency and fulfilling application requirements.\nTo illustrate the practical applications of this architectural paradigm, consider the following implementation scenarios:\n\nBookmark Management System: A client application designed to store and retrieve user bookmarks directly from the home server.\nFile Synchronization Utility: Similar to the open-source Syncthing project, this type of application would facilitate direct file synchronization between the client and the home server.\nText Snippet Repository: A lightweight application for creating, storing, and retrieving short text fragments or code snippets as pastebin\n\nThese implementations leverage the Pubky Core protocol to establish secure, efficient, and direct data exchange channels between the client and the home server, while the user remains with ownership of their data."},"App-Architectures/3.-Global-Aggregators":{"title":"3. Global Aggregators","links":[],"tags":[],"content":"\nThis architectural pattern implements a distributed system model centered around a global aggregation layer, eliminating the need to fetch data from a multitude (maybe thousands!) of homesevers by the client. The core component of this design is a centralized global aggregator that interfaces with multiple home servers, consuming events from each in a unified manner.\nKey features of this architecture include:\n\nCentralized Event Processing: The global aggregator serves as a single point of convergence for event streams originating from disparate home servers across the network.\nPolicy-Driven Filtering: The aggregators can optionally implement a configurable set of policies and filtering rules, allowing for dynamic event processing based on predefined criteria.\nClient Flexibility and Aggregator Choice: Clients consume data from the global aggregator stream. However, if a client finds the enforced rules of one aggregator unsuitable, it retains the flexibility to switch to an alternative global aggregator that better aligns with its requirements or selectively look for the homeservers itself.\nScalable Event Distribution: By centralizing the aggregation process, this architecture facilitates efficient event distribution to multiple clients, potentially reducing redundant processing and network overhead.\n"},"App-Architectures/4.-Custom-Backend":{"title":"4. Custom Backend","links":["Pubky-App/Introduction"],"tags":[],"content":"\nThis architectural design introduces a more sophisticated data flow model, incorporating an intermediary backend layer between the client application and the home server. This backend functions as a middleware, enhancing the system’s flexibility and data processing capabilities.\nThe backend can be potentially comprised with many components. These components will depend on the client app needs, but these are the main ones\n\nIndexer: Responsible for data normalization, ensuring consistent data structures and optimizing query performance.\nAggregator: Implements event filtering logic, allowing for selective data propagation based on predefined criteria.\n\nThis architecture supports two distinct data consumption patterns:\na) For scenarios requiring both data normalization and event filtering, the client interacts with the backend layer, as an endpoint. The aggregator processes the event stream from the home servers, applying filtering rules before passing the data to the indexer for normalization.\nb) In cases where only data normalization is necessary, the backend can bypass or not implement the aggregator, consuming events directly from the home server via the indexer.\nThis modular approach allows for fine-grained control over data processing, enabling efficient resource utilization and optimized client-side performance based on specific application requirements.\nAn example of a complex backend that does aggregation, normalization, indexation, filtering (compliance) and powerful inference is Pubky-Nexus, the backend that powers the Pubky App social features."},"Concepts/1.Web-of-Trust":{"title":"1.Web of Trust","links":[],"tags":[],"content":"The “Web of Trust” is a decentralized trust model used in cryptography, particularly in systems like PGP, GnuPG, and other OpenPGP compatible systems, to establish the authenticity of the binding between a public key and its owner.\nThis model is an alternative to the centralized trust model of a Public Key Infrastructure (PKI), which relies on a certificate authority (CA) or a hierarchy of such authorities.\nThe concept, first introduced by PGP creator Phil Zimmermann in 1992, allows users to accumulate keys from others and designate them as trusted introducers. Over time, users distribute a collection of certifying signatures with their keys, expecting that anyone receiving these will trust at least one or two of the signatures. This process leads to the emergence of a decentralized, fault-tolerant web of confidence for all public keys, enabling a peer-to-peer rating system that verifies public keys and their owners without relying on a central identity authority."},"Concepts/2.Censorship":{"title":"2.Censorship","links":[],"tags":[],"content":"Censorship in the digital age is a complex and multifaceted issue, affecting how information is shared, accessed, and controlled. It’s not just about blocking content; it’s about the power dynamics at play, the implications for freedom of expression, and the challenges of maintaining privacy and security in an increasingly interconnected world.\nUnderstanding Censorship\nCensorship can take many forms, from the simple act of removing content from public view to more sophisticated methods like deepfakes and disinformation campaigns. It can be enforced by governments, corporations, or even individuals, often with the intention of controlling narratives, suppressing dissent, or protecting commercial interests.\nImpact on Freedom of Expression\nThe internet was hailed as a tool for democratizing information and fostering freedom of expression. However, censorship poses a significant threat to these ideals. It can stifle the flow of ideas, suppress dissenting voices, and create echo chambers where only certain perspectives are heard.\nChallenges\nIn the digital age, censorship is not just about blocking access to information. It’s about navigating a landscape where information can be manipulated, where identities can be stolen, and where privacy is increasingly under threat. The challenge lies in finding ways to protect freedom of expression and privacy in the face of these threats.\nThe Role of Technology\nTechnology plays a crucial role in both enabling and combating censorship . On one hand, it provides tools and platforms for the dissemination of information. On the other hand, it can be used to censor content, track users, and manipulate public opinion. The key is to leverage technology in a way that supports freedom, transparency, and accountability."},"Concepts/3.Credible-Exit":{"title":"3.Credible Exit","links":["Technologies/DNS"],"tags":[],"content":"It is a concept that emphasizes the ability for users to leave a platform or service without being locked in, maintaining control over their data and experiences. This concept is gaining traction as a way to ensure user autonomy and foster competition among service providers.\nThis substack post by Gordon Brander is a good read as introduction to the topic. The following is a summary:\nExamples of Credible Exit\n\nDNS: Allows users to move domain names between hosting providers, preventing vendor lock-in and promoting competition.\nEmail: Offers the ability to switch between email service providers and save emails locally, enhancing user control over personal data.\nPodcasts: Supports importing and exporting subscriptions, facilitating easy transition between platforms.\nMirror.xyz: Utilizes distributed protocols for data replication and storage, ensuring data can be reconstructed without relying on central services.\nGitHub: Provides credible exit for code through Git, allowing users to clone repositories and contribute to open-source projects.\nMastodon: Enables federation between different instances, allowing users to move between servers without losing their data.\n\nImportant Aspects of Credible Exit\n\nProtocols: The foundation of credible exit, enabling communication and data transfer between systems.\nData Importance: Differentiating between basic data (content created by users) and generated data (interactions, likes, comments), which may require different approaches for exit.\nDimensions of Credible Exit: Including the ability to export data, sync data across platforms, use data in useful formats, and store data in local files.\n\nChallenges and Considerations\n\nStatic Exports: While GDPR regulations allow for data exports, the static nature of these exports can limit their utility for ongoing use.\nData Formats: The importance of using common, useful formats for data to ensure it can be utilized elsewhere.\nInteroperability: The potential for multiple apps to share data through permissionless APIs, enhancing broad interoperability.\n"},"ELI5":{"title":"ELI5","links":[],"tags":[],"content":"Explaining Pubky Core Like You’re 5 Years Old\nImagine you have a special toy castle that you built, and you want your friends to come and play with it. Maybe you set up your castle in your backyard, or in the park, or at your grandma’s house. You tell your friends where it is so they can come play.\nNow, suppose you chose the park, but it is closed, or someone says you can’t keep your castle there anymore. No worries!\nYou Move the Castle: You pick up your castle and set it up somewhere else, like your backyard.\nYou Tell Your Friends: You let your friends know the new spot so they can still come and play.\nSo, what is Pubky Core?\n**Pubky Core is like you being in charge of where your stuff lives on the internet. Even if things change—like someone tries to block your stuff or you decide to move it—you have the power to:\n**\nChoose Where Your Data Lives: Just like you decide where to place your castle, Pubky Core lets you decide where your information is stored online.\nMove It When Needed: If you have to change where your data is kept (like moving your castle), you can do that easily.\nUpdate the Directions: You can tell everyone where to find your data, so your friends can always access it, no matter where it is.\n**Why is Pubky Core Special?\n**\nYou’re in Control: You decide where your data is stored on the internet, and you can change it whenever you need to.\nStay Connected Despite Changes: If something happens—like censorship or a website blocking you—you can move your data to a new place, and people can still find it.\nFreedom to Share: No one can stop you from sharing your stuff. You always have the ability to let others access your data by updating its location.\n**In Simple Terms:\n**\nYou Control the Location of Your Data: Just like moving your castle, you choose where your online information lives.\nAdaptable to Change: If things change or someone tries to stop you, you can move your data and keep sharing without losing anything.\nAlways Accessible: By updating where your data is stored, your friends (or anyone) can always find and see it.\nSo, Pubky Core empowers you to manage where your data is on the internet. It ensures that even if things change—like being censored or needing to move—you can keep your data accessible and tell others where to find it. It’s all about you being in control, just like deciding where to set up your favorite toy so your friends can always come and play!"},"Pubky-App/Backend/Aggregator":{"title":"Aggregator","links":["Pubky-Core/Data-Stores","Concepts/2.Censorship"],"tags":[],"content":"Pubky Aggregators\nAggregators are specialized reducers or gatekeepers that continuously scan and collect data from various sources, such as data stores. They decide what data to allow in and what to keep out.\nWhen the aggregator receive new events, it evaluates it against its predefined criteria. If the data meets the criteria, the aggregator allows it to pass through, making it available for further processing or storage. However, if the data doesn’t meet the criteria, the aggregator blocks it, preventing it from entering the system.\nBy controlling the flow of information, aggregators play a crucial role in maintaining data quality, preventing information overload, and ensuring that only the most valuable and relevant data is used.\nCharacteristics\n\nFine-grained access controls: Users and aggregators have granular control over what data is shared, with whom, and under what conditions, ensuring selective and secure data exchange.\nEfficient data synchronization: Merkle trees enable fast and efficient synchronization of incremental changes from data stores, reducing the overhead of data aggregation.\nNormalized data schemas: Standardized data schemas facilitate interoperability between services, making it easier to integrate and exchange data across the network.\nPublic and niche aggregators: The network supports both large-scale, public aggregators for discoverability and smaller, niche aggregators that cater to specific communities or use cases.\nCore user graph expansion: The aggregation process starts with a core user graph and expands outward through connections, enabling the network to grow organically and efficiently.\nCensorship resistance: The system’s censorship resistance is achieved through a decentralized aggregation architecture, where data aggregation is distributed across a network of independent, autonomous aggregators. This design ensures that no single entity or node has control over the aggregation process, making it more resilient to censorship attempts.\n"},"Pubky-App/Backend/Indexer":{"title":"Indexer","links":["Pubky-Core/Data-Stores"],"tags":[],"content":"The Indexer is a specialized component that plays a crucial role in the system by normalizing and transforming the aggregated data from multiple data stores into a unified view. This enables cross-data store search, queries, and discovery, allowing users to access and analyze data from various sources in a seamless and efficient manner.\nCharacteristics\n\nData Normalization: The Indexer normalizes the data from multiple sources, handling differences in format, structure, and schema. This involves transforming the data into a consistent format, resolving data conflicts, and ensuring that the data is accurate and reliable.\nData Transformation: The Indexer transforms the normalized data into a unified view, making it possible to query and analyze the data across multiple data stores. This unified view enables users to access data from different sources as if it were a single, cohesive dataset.\nData Integrity: The Indexer ensures data integrity through secure synchronization protocols, guaranteeing that the indexed data is consistent and up-to-date. This involves implementing measures to prevent data corruption, ensuring that data updates are propagated across all data stores, and maintaining a high level of data quality and accuracy.\nScalability: The Indexer is designed to handle large volumes of data from multiple sources, ensuring that it can scale to meet the needs of a growing user base and increasing data demands.\n\nBy normalizing, transforming, and ensuring the integrity of the data, the Indexer provides a robust and scalable solution for cross-data store search, queries, and discovery"},"Pubky-App/Backend/Introduction":{"title":"Introduction","links":["Pubky-App/Backend/Aggregator","Pubky-App/Backend/Indexer","Pubky-Core/Data-Stores","Pubky-App/Backend/Web-Server","Pubky-App/Client/Introduction"],"tags":[],"content":"The Backend is responsible for collecting (aggregators) and organizing (indexer) data from various sources, known as data stores.\n\nImagine you’re trying to find a specific document in a large library. The backend is like a librarian who searches through the shelves, finds the right documents, and prepares them for you to use. This ensures that the data is accurate, up-to-date, and in a format that’s easy to work with.\nMain components\n\nAggregators execute a data retrieval protocol to obtain data from data storage, initiating a process that retrieves and collects data from various sources.\nIndexers receive aggregated data from the Aggregators and initiate a rigorous data normalization process, transforming and converting the data into a standardized format to ensure consistency and accuracy.\nWeb servers provide the requested data to Pubky client\n"},"Pubky-App/Backend/Web-Server":{"title":"Web Server","links":["Pubky-App/Client/Features/Tags","Pubky-App/Client/Features/Profiles","Technologies/Paykit"],"tags":[],"content":"The system comprises a suite of backend services that orchestrate the integration of data feeds, search functionality, and user interface configurations. The system provides a unified platform for data ingestion, processing, and presentation, enabling seamless interactions between the frontend and backend components.\nServices\n\nFeeds - Curated views of aggregated data presented to users. Can include timelines, tags, profiles, etc.\nSearch - Services that index aggregated data and enable full text/attribute searches.\nIdentity - It provides single sign-on through self-sovereign credentials.\nPayments - It handles microtransactions like tipping within a peer-to-peer economy.\n\nArchitecture\nThe web server can be designed and implemented using various architectural patterns, depending on the specific requirements of the data request workflow. Two prominent architectural styles that can be employed are:\n\nMonolithic Architecture: A single-tiered architecture where the web server is constructed as a self-contained unit, encompassing all necessary components and functionality. This approach is characterized by a tightly-coupled design, where all components are integrated into a single executable or deployable unit.\nMicroservices Architecture: A multi-tiered architecture where the web server is decomposed into a collection of loosely-coupled, independent services that communicate with each other using APIs and messaging protocols. Each microservice is responsible for a specific business capability or data domain, enabling greater flexibility, scalability, and resilience.\n\nThe choice of architecture depends on various factors, including data request patterns, traffic volume, performance requirements, development team expertise, and maintenance considerations."},"Pubky-App/Client/Features/Bookmarks":{"title":"Bookmarks","links":[],"tags":[],"content":"Bookmarks\nBookmarks are a feature that allows you to privately save post for later reference. Here are some ways you can use bookmarks:\n\nSave for later reading: If you come across a post that you don’t have time to read or engage with immediately, you can bookmark it to read later when you have more time.\nReference material: Bookmarks can serve as a repository for tweets that contain useful information, such as articles, tutorials, or resources, that you might need to refer to later. In that case, you can organise the posts by topic.\nPrivate note-taking: Bookmarks can serve as a private note-taking system, allowing you to save tweets that you want to remember without having to publicly like or retweet them.\n\nTo bookmark a post, simply click or tap the “Bookmark” icon (it looks like a ribbon) on the post. You can access your bookmarked posts by clicking the button on top of the page."},"Pubky-App/Client/Features/Layouts":{"title":"Layouts","links":[],"tags":[],"content":"Layouts\nPubky client offers multiple customizable UI layouts for users that prefer different column, grid, and list layouts for their feeds."},"Pubky-App/Client/Features/Notifications":{"title":"Notifications","links":["Pubky-App/Client/Features/Posts"],"tags":[],"content":"Notifications\nPubky client tracks various event or activities the user may be interested in, and provides relevant notifications for interactions and other relevant activity to the user. Notifications are a way to keep you informed about what’s happening in the app, even when you’re not actively browsing your timeline.\nHere are some common types of notifications you might receive:\n\nMentions: When someone mentions you in a post, you’ll receive a notification. This means they’ve included your public key (pk:pubky) in their post.\nReplies: If someone replies to one of your post, you’ll get a notification.\nLikes: When someone likes one of your posts, you’ll receive a notification.\nRe-posts: If someone re-posts one of your posts, you’ll get a notification.\nFollows: When someone new follows you, you’ll receive a notification.\nQuote Posts: If someone quotes one of your posts, you’ll receive a notification.\n"},"Pubky-App/Client/Features/Perspectives":{"title":"Perspectives","links":[],"tags":[],"content":"Perspectives\nUsers can save any custom-filtered view or feed as a “perspective” which is basically a custom template of settings of tags, weights, users, reach, and trends. Perspectives can also save custom UI layouts for the user."},"Pubky-App/Client/Features/Posts":{"title":"Posts","links":["Pubky-App/Client/Features/Tags"],"tags":[],"content":"Posts\nIn Pubkey client, a post is a message that a user publishes on the platform. Posts are the core content and they can contain a variety of information, including:\n\nText: There is not text limitation of plain text, which can include words, phrases, sentences, or even just a single character.\nMedia: Post can include various types of media, such as images and videos.\nTags: It is a keyword or phrase preceded by the ”#” symbol, which help categorize and make post discoverable by topic.\nMentions: References to other Pubky users, denoted by the “pk” keyword which notify them of the post.\nLinks: URLs to external websites, articles, or other online content.\nEmojis: Small images or icons used to convey emotions or add tone to the tweet.\n\nUsers also can re-post and reply to posts"},"Pubky-App/Client/Features/Profiles":{"title":"Profiles","links":[],"tags":[],"content":"Profiles\nIn Pubky client, a profile refers to a user’s personal page on the app, which displays their information, posts, and other content. A Pubky profile is a unique identity that represents a public-key.\nHere are some key components of a Pubky profile:\n\nUsername: A unique handle or identifier that represents the user, often preceded by the “pk” keyword(e.g. pk:uudfeafc1c6dhxxnaiyuzss5ln9i1ikpb8syht46qpnx4ksi6ho).\nProfile picture: A small image that represents the user, often a photo or logo.\nBio: A short description of the user, often including information about their interests, profession, or personality.\nWebsite: A link to the user’s personal website, blog, or other online presence.\nPosts: The user’s posts, which are displayed in reverse chronological order (newest tweets first).\nFollowers: The number of users who follow the profile, indicating the size of their audience.\nFollowing: The number of users that the profile follows, indicating the accounts they’re interested in.\nLists: The number of lists the user has created or been added to, which are curated groups of accounts.\n"},"Pubky-App/Client/Features/Search":{"title":"Search","links":[],"tags":[],"content":"Search\nWhile Tags &amp; Filters are the primary sorting tools, the app also provides limited traditional search capabilities."},"Pubky-App/Client/Features/Tags":{"title":"Tags","links":["tags/Pubky","tags/privacy","tags/segwit"],"tags":["Pubky","privacy","segwit"],"content":"Tags\nThey are keywords or phrases that are added to a tweet to help users find and engage with the content. Users can publicly assign contextual tags, like hashtags, to any other user or post. Tags can be used to filter posts and users. Users can also choose custom weighting of tags when filtering.\nHow do tags work?\n\nHashtags: Tags are denoted by the ”#” symbol, followed by a word or phrase. For example,Pubky,privacy, orsegwit.\nClickability: When you click on a tag, Pubky client takes you to a page that displays all the posts that have used that same tag.\nDiscovery: Tags help users discover new content, accounts, and conversations related to a specific topic.\nCategorization: Tags help categorize posts, making it easier for users to find and engage with content that interests them.\n"},"Pubky-App/Client/Features/Trends":{"title":"Trends","links":[],"tags":[],"content":"Trends\nPubky client can provide statistical views of the data it has access to and then establish visualizations and leaderboard lists of trending posts, tags, and users."},"Pubky-App/Client/Introduction":{"title":"Introduction","links":["Pubky-App/Backend/Introduction","Concepts/3.Credible-Exit","Pubky-Core/Introduction","Technologies/Paykit"],"tags":[],"content":"Pubky Client\n\nThe Pubky client will be available as both a desktop application and a hosted website service (standard website) that allows users to interface with the social media layer of Pubky Backend using Synonym hosted services.\nUsing the library analogy again, the Pubky Client is like a personalized research assistant who takes the prepared documents from the librarian (backend) and creates a customized report just for you. This report is designed to be easy to read and understand, with all the relevant information presented in a clear and concise manner.\n\n\nUsers are able to take control of the data and exit the Synonym hosted services and run their own without hampering discoverability (credible exit).\n\n\nPubky client uses the open Pubky Core for nearly all features, allowing users to avoid censorship by choosing self-hosting or alternate hosts without losing followers or integrity. \n\n\nPubky also features support for paykit, our open payment protocol for coordinating payments among peers supporting various methods. This allows users to create sub-accounts from master wallets for familiar payment experiences. This suite of features removes any requirement from Synonym to custody user funds, while allowing for users to set up subscriptions, recurring payments, paywalls, etc, in a P2P way. This feature will not be in the first launch version of Pubky app, but it is worth noting that next year we will enable all users to buy and sell data in this way.\n\n\nCommunities facilitate moderation and discovery around shared interests.\n\n"},"Pubky-App/Introduction":{"title":"Introduction","links":["Pubky-Core/Data-Stores","Pubky-App/Introduction","Pubky-App/Backend/Aggregator","Pubky-App/Client/Features/Search","Pubky-App/Backend/Introduction","Pubky-App/Client/Introduction","Pubky-Core/Introduction","Pubky-Core/Pkarr/0.Introduction"],"tags":[],"content":"\n\nSynonym will be initially hosting: Data stores and Pubky App\n\nOverview\nPubky-app’s initial focus is building a decentralized social media protocol.\nKey aspects\n\nData Ownership: Users have full autonomy over their data, hosting it on independent data stores that are decentralized and distributed across the network. This approach enables users to maintain control and ownership of their data, while also ensuring data sovereignty and privacy.\nProfiles: The system employs a decentralized data storage approach, where post, comment, and like data are stored in association with user profiles.\nAggregators collecting social graphs\nFeeds of followings’ activities\nSearching profiles and posts\nNotification delivery through aplication backends\nDistributed moderation through user blocking\n\nComponents\nThe Pubky App is a complex system that can be broken down into two main components: the backend and the client. These two pieces work together to provide a seamless user experience.\nBackend: The Data Organizer\nIt collects and organizes data from various sources, processing it into a usable format.\nClient: The User Interface\nIt is the part of the Pubky App that you interact with directly. It’s responsible for taking the organized data from the Backend and presenting it to you in a visually appealing and easy-to-understand way.\nMVP Architecture\nThe early versions of Pubky app take some shortcuts over the Pubky Core design. The MVP app is centralized, therefore we saved time and complexity by aggregating functionality into fewer components. The main two components are the Homeserver and the Indexer\n\nThe Homeserver fulfils the function of data stores, Pkarr republishing for users, identity-provider (Oauth-like sign-in). Users maintain a trust relationship with the Homeserver.\nThe Indexer fulfils the function of the backend for the Pubky App.\n"},"Pubky-Core/Data-Stores":{"title":"Data Stores","links":["Pubky-Core/notes/2.Incentives"],"tags":[],"content":"The network is composed of multiple, independent data stores, which provides censorship resistance and ensures that no single entity controls the flow of information.\nData Storage and Access\n\nClient-side encryption: Data at rest is encrypted using users’ public keys, ensuring that only the data owner possesses the decryption key and has exclusive access to the encrypted data.\nOptional data publication: Users have the option to publish data publicly, making it accessible to all, or maintain control over access through fine-grained permissions.\n\nData Retrieval and Synchronization\n\nAPI and Pub/Sub access: Authorized services can access data through a RESTful API or via a publish-subscribe (Pub/Sub) messaging system, enabling efficient and scalable data retrieval.\nMerkle tree-based versioning: The system employs Merkle trees to manage versioning and conflict resolution, ensuring efficient data synchronization and minimizing data inconsistencies.\n\nDecentralized Storage Architecture\n\nFederated data stores: Data stores can be operated by individuals, cooperatives, or commercial entities, with the option for anonymous operation, promoting a decentralized and resilient storage ecosystem.\nRedundancy through replication: Data is replicated across multiple data stores to ensure high availability and redundancy, minimizing the risk of data loss or unavailability.\n\nIncentivizing Data Availability\n\nIncentive mechanisms: The system incorporates incentives, such as service fees or peer-to-peer micropayments, to encourage data availability and storage providers to maintain high uptime and data accessibility.\n\nUser Data Control and Credible Exit\n\nUser-centric data control: Users retain control over their data even in the event of a data store outage or termination, thanks to credible exit options that ensure data portability and availability.\n"},"Pubky-Core/Introduction":{"title":"Introduction","links":["Pubky-Core/Data-Stores","Pubky-Core/Pkarr/0.Introduction","Concepts/3.Credible-Exit","App-Architectures/1.-Introduction","App-Architectures/2.-Client---Homeserver","App-Architectures/4.-Custom-Backend","Concepts/1.Web-of-Trust","Pubky-App/Introduction"],"tags":[],"content":"Pubky Core Overview\n\nPubky Core is built on a few core concepts:\n\n\nData Stores - Decentralized data storage nodes that host user data. Data is encrypted at rest.\n\n\nPkarr - Self-issued public keys that function as sovereign, publicly addressable domains are used to resolve the previous components.\n\n\nPubky Core’s distributed architecture aims to provide user autonomy through credible exit between interchangeable components.\n\nPubky App Architectures can be very diverse. From simple web client applications that connect to a single homeserver for data storage and retrieval to complex backends  that do aggregation and powerful inference over many homeservers creating abstractions such as social media with web of trust.\n\nTarget Users\nPubky Core is made for developers and builders of internet software products. We will actively work to cultivate a community of builders and startups using our tech.\nPubky App is made for anyone interested in social media and online publishing that wants new ways to control their data and more control over which posts they see.\nWhy? What is the reward?\nThe reward for everyone is a more open, privacy-focused, usable, modular and secure web. The reward for Synonym as lead of this project is to be positioned to disrupt Big Tech as an industry, gain user recognition and hopefully reputation through the effort of building a decentralized ecosystem. The ultimate potential is for Synonym to become a major player in online publishing &amp; social media, while also monetizing in ways similar to Google (e.g., search and aggregation over the web → search / aggregation and tools for sovereign data stores), as well as opportunities to introduce new users to our ecosystem of products and services (e.g., bitcoin payments infrastructure)"},"Pubky-Core/Pkarr/0.Introduction":{"title":"0.Introduction","links":["Technologies/DNS","Technologies/DHT","Technologies/Mainline-DHT","Technologies/HTTPS","Technologies/DoH","Pubky-Core/Pkarr/4.Architecture","Pubky-Core/Pkarr/2.Getting-Started-with-Pkarr"],"tags":[],"content":"Public-Key Addressable Resource Records\nPkarr is a revolutionary system that bridges the gap between the Domain Name System (DNS) and peer-to-peer overlay networks. It allows self-issued public keys to function as sovereign, publicly addressable domains. This means that anyone with a private key can have a domain that is accessible to everyone.\nThe core idea is to streamline the process of publishing and resolving resource records for keys, leveraging the Distributed Hash Table (DHT) for efficient and scalable data distribution.\nKey Features\n\nSimplicity: Pkarr streamlines the integration between DNS and peer-to-peer networks.\nSovereignty: Public keys can be used as domains, enabling users to maintain control over their digital identities.\nAccessibility: The system is designed to be accessible to anyone capable of maintaining a private key.\nScalability and Resilience: Designed with scalability and resilience in mind, using the Mainline DHT for storing ephemeral data, and employing caching strategies to minimize DHT traffic.\nCompatibility with Existing Applications: Supports existing applications through DNS over HTTPS (DoH) queries to Pkarr servers, ensuring broad compatibility.\n\nHow It Works\n\nPublishing Records: To publish resource records for a key, create a small encoded DNS packet (⇐ 1000 bytes), sign it, and publish it on the DHT. This can be done directly or through a relay if necessary.\nResolving Records: To find resources associated with a key, applications can query the DHT directly or through a relay, verifying the signature themselves.\nFallback for Existing Applications: Applications unaware of Pkarr can make normal DNS Queries over HTTPS (DoH) to Pkarr servers, ensuring accessibility.\nCaching and Republishing: Both clients and Pkarr servers cache records extensively to improve scalability. The DHT drops records after a few hours, necessitating periodic republishing to keep records alive.\n\nFor more technical details on Pkarr’s architecture and how it works, refer to the architecture note.\nGetting Started\nTo start using Pkarr, you can visit the web app demo or explore the Rust examples provided in Pkarr repository."},"Pubky-Core/Pkarr/1.Why-Pkarr":{"title":"1.Why Pkarr?","links":[],"tags":[],"content":"This note explores the motivation behind Pkarr, addressing the challenges of distributed semantics, databases, and discovery.\nIn pursuit of a sovereign, distributed, and open web, we identify three challenges:\n\n\nDistributed Semantics Everything expressed as keys and metadata\nDeveloping interoperable semantics for verifiable metadata about a set of public-keys that form a digital identity, complete with reputation, social graph, credentials, and more.\n\n\nDistributed Database(s) Anyone can host the data\nVerifiable data alone is insufficient; a host-agnostic database is essential for an open web, as opposed to walled gardens.\n\n\nDistributed Discovery Where is the data?\nBut before that, you need to efficiently and consistently discover the multiple hosts for a given data-set.\n\n\nAddressing Distributed Discovery first makes the most sense for several reasons:\n\n\nThe difficulty of these three challenges inversely correlates with their order.\n\n\nThe marginal utility of solving these challenges positively correlates with their order.\nIn existing and emerging open social network protocols, users do tolerate limited interoperability between clients, second-class identifiers controlled by hosting or domain servers, inefficient or non-existent conflict-free replication between data stores, and the absence of local-first or offline support. However, their most common complaints involve unavailability, censorship, deplatforming, and difficulty in securely managing keys.\n\n\nDistributed Discovery offers the greatest assured leverage by abstracting over current and emerging solutions for (1) and (2) as they compete, complement, and develop independently, all while maintaining the same long lasting identifier, so you don’t have to start from scratch or be locked in.\n\n"},"Pubky-Core/Pkarr/2.Getting-Started-with-Pkarr":{"title":"2.Getting Started with Pkarr","links":["Pubky-Core/Pkarr/0.Introduction","Technologies/DNS","Technologies/DHT","Technologies/HTTPS","Technologies/DoH","Pubky-Core/Pkarr/4.Architecture"],"tags":[],"content":"This guide will help you understand how to publish and resolve resource records using pkarr.\nPublishing Resource Records\nTo publish resource records for your key, you need to sign a small encoded DNS packet (⇐ 1000 bytes) and publish it on the DHT. This can be done through a relay if necessary.\nResolving Resource Records\nTo resolve some key’s resources, applications can query the DHT directly or through a relay. They will then verify the signature themselves.\nDNS Queries Over HTTPS\nExisting applications unaware of pkarr can make normal DNS Queries over HTTPS (DoH) to pkarr servers.\nCaching and Scalability\nClients and pkarr servers cache records extensively to minimize DHT traffic and improve scalability. The DHT drops records after a few hours, so it’s important to republish records periodically.\nNext Steps\nFor more technical details on pkarr’s architecture and how it works, refer to the architecture note."},"Pubky-Core/Pkarr/3.Expectations":{"title":"3.Expectations","links":["Pubky-Core/Pkarr/0.Introduction","Technologies/DHT","Pubky-Core/Pkarr/1.Why-Pkarr"],"tags":[],"content":"Understanding the expectations and limitations of pkarr is crucial for effective use. This note outlines what pkarr is not and what users should expect.\nNot a Storage Platform\npkarr is not a storage platform. Records are ephemeral and need to be refreshed regularly to remain on the DHT.\nNot a Real-time Communication Medium\npkarr is not designed for real-time communication. It is optimized for infrequent updates and heavy caching to reduce traffic.\nRate Limiting and Proof of Work\nExpectations include enforcing harsh rate-limiting and possibly demanding proof of work for updates.\nCaching and Propagation Time\nRecords are heavily cached, and updates might take some time to propagate. In case of a cache miss, querying the DHT might take a few seconds.\nNext Steps\nFor a deeper understanding of why pkarr was created and its motivation, refer to the why pkarr? note."},"Pubky-Core/Pkarr/4.Architecture":{"title":"4.Architecture","links":["Pubky-Core/Pkarr/0.Introduction","Technologies/DNS","Technologies/Mainline-DHT","Technologies/HTTPS","Technologies/DoH"],"tags":[],"content":"In-depth look at the architecture of pkarr, including its components and how they interact.\nComponents\n\nClient: Applications or users that publish or query resource records.\nRelay: Optional intermediary that helps clients behind NAT or firewall to communicate with the DNS.\nDNS: The overlay network used for storing and retrieving resource records.\nRepublisher: Services that keep resource records alive on the DNS by periodically republishing them.\n\nInteraction Flow\n\nPublishing: Clients publish resource records to the DNS through a relay.\nRepublishing: Clients can request republishing of their records to ensure they remain available on the DNS.\nQuerying: Clients query the DNS for resource records, either directly or through a relay.\n\nKey Technologies\n\nMainline DHT: Pkarr uses the Mainline DNS as its overlay network, specifically BEP44 for storing ephemeral data.\nDNS over HTTPS (DoH): For applications unaware of Pkarr, DoH is used to resolve domains.\n"},"Pubky-Core/notes/1.Adoption":{"title":"1.Adoption","links":["Concepts/2.Censorship"],"tags":[],"content":"Pubky Adoption\nThis note is indicative and creative. There is no set on stone plans for realizing adoption, these are just ideas. Realizing the full potential of Pubky relies on network effects through mainstream user onboarding:\n\n\nLegacy centralized imports ease migration paths for established communities and profiles.\n\n\nSimplified wallet and key management avoids barriers through friendly UX.\n\n\nDefault public profiles paired with granular privacy, encourage open participation.\n\n\nProgressive web apps (PWA) maintain familiar experience across any device.\n\n\nIncentivized discovery games spark initial engagements like following interesting accounts.\n\n\nFederation with aligned systems like Mastodon expands the userbase through existing clusters.\n\n\nGrassroots developers support localized languages/cultures for global inclusion.\n\n\nDocumentation, scholarships and bounties lower the skill floor for contributing back to protocols.\n\n\nOverall, Pubky relies on being ready and available at the right time and right place. Most likely users will only discover Pubky during a Censorship attack."},"Pubky-Core/notes/2.Incentives":{"title":"2.Incentives","links":[],"tags":[],"content":"Pubky Incentives\nThis note is indicative and creative. Nothing is planned concretely for Pubky incentives. For the Pubky ecosystem to function at scale, it relies on incentives that encourage participation and uphold the user experience:\n\n\nData storage fees pay stores for availability and throughput.\n\n\nTipping and subscriptions reward high-quality contributors and curators.\n\n\nAdvertising supports free-tier services and indexes through contextual/non-intrusive formats.\n\n\nValidation bonds and slashing conditions secure protocol compliance.\n\n\nData marketplace sales enable professional content creators to profit directly.\n\n\nJob boards and service directories create opportunities within the emerging peer-to-peer economy.\n\n\nTogether, these push the system towards collective benefit over individual maximization."},"Pubky-Core/notes/3.Protocols":{"title":"3.Protocols","links":["Technologies/Paykit"],"tags":[],"content":"Pubky Protocols\nThis note is indicative and highly creative. We have not yet explored much about the open protocols that enable independent implementations:\nPubky Data - Definition of normalized data schemas for user profiles, content types, relationships etc. Allows unified querying across services.\nPubky Sync - Mechanism for efficiently synchronizing incremental changes between data stores, aggregators, and consumers using Merkle trees.\nPubky Search - Format for full-text search indices and queries across aggregated Pubky Data. Enables cross-platform discovery.\nPubky Payments - Decentralized and interoperable payment protocol for microtransactions like tips, subscriptions and purchasing goods/services.\nPubky Identity - Self-sovereign digital credentials for authentication without centralized authorities like usernames/passwords.\nPubky Federation - Standard for distributed moderation and cross-instance relationships between interconnected but independent communities."},"TLDR":{"title":"TLDR","links":["Pubky-App/Introduction","Pubky-Core/Data-Stores","Pubky-App/Backend/Aggregator","Applications"],"tags":[],"content":"Pubky App is a decentralized alternative to social media platforms like Twitter. It uses a distributed architecture where:\n\nUsers host their own data on independent data stores\nServices aggregate data across stores into a unified view\nFeeds and search present curated views of the aggregated data\nApplication back-ends integrate features without centralized control\n\nThe end goal is to give individuals self-sovereign digital identity and true ownership over social profiles/activity without fear of data misuse or account bans by any single entity.\nArchitecture overview.\n"},"Technologies/DHT":{"title":"DHT","links":["Technologies/Mainline-DHT","Concepts/2.Censorship"],"tags":[],"content":"Distributed Hash Table - DHT\nIt is a decentralized key-value store that allows for efficient data retrieval in a distributed system. Unlike traditional databases, DHTs do not rely on a central server to manage data. Instead, they use a hash function to map keys to nodes in the network, enabling data to be stored and retrieved across multiple nodes.\nA relevant example of DHT for Pubky is the Mainline DHT that is used primarily by the BitTorrent Network.\nKey Features\n\n\nDecentralization: DHTs operate without a central authority, making them highly resilient to failures and censorship.\n\n\nScalability: They can easily scale to accommodate more data and users by adding more nodes to the network.\n\n\nEfficiency: By distributing data across multiple nodes, DHTs can provide fast access to data without the need for a central server.\n\n\nApplications\nDHTs are widely used in various applications, including:\n\n\nP2P Networks: They are the backbone of peer-to-peer (P2P) networks, enabling the sharing of files and resources among users.\n\n\nContent Delivery Networks (CDNs): DHTs help in efficiently distributing content across a global network of servers, improving load balancing and reducing latency.\n\n\nChallenges\nDespite their advantages, DHTs face several challenges, including:\n\n\nSecurity: Ensuring data privacy and integrity in a decentralized environment.\n\n\nConsistency: Achieving consistency across the distributed network, especially in the presence of node failures or network partitions.\n\n\nPerformance: Balancing the trade-off between data distribution and access latency.\n\n\nDHTs represent a significant advancement in distributed systems, offering a scalable and efficient solution for data storage and retrieval in decentralized environments."},"Technologies/DNS":{"title":"DNS","links":[],"tags":[],"content":"Domain Name System - DNS\nIt translates human-readable domain names (e.g., www.example.com) into IP addresses that computers use to identify each other on the network. This process simplifies internet navigation by allowing users to access websites using memorable names instead of numerical addresses."},"Technologies/DoH":{"title":"DoH","links":["Technologies/DNS","Pubky-Core/Pkarr/0.Introduction","Technologies/HTTPS"],"tags":[],"content":"DNS over HTTPS - DoH\nIt is a security protocol that encrypts DNS queries and responses, enhancing privacy and security by preventing eavesdropping and tampering. In the context of pkarr, DoH plays a crucial role in ensuring that DNS queries made to resolve public-key addresses are secure and cannot be intercepted or manipulated by third parties.\nKey Points about DoH\n\n\nEncryption: DoH encrypts DNS traffic, making it unreadable to anyone who might intercept the data. This is achieved by sending DNS queries and responses over HTTPS connections, utilizing port 443, the standard port for HTTPS traffic.\n\n\nPrivacy and Security: By encrypting DNS queries, DoH significantly increases privacy and security. It prevents Internet Service Providers (ISPs), governments, and hackers from monitoring or altering DNS requests.\n\n\nStandardization and Adoption: DoH has been adopted by major internet brands, including Apple, Microsoft, and Google, to enhance online security. It was first implemented by Mozilla in 2018, and since then, it has become a standard for secure DNS communication.\n\n\nCompatibility and Implementation: DoH can be enabled in browsers and operating systems, allowing users to benefit from its privacy and security features. However, it’s important to ensure compatibility with existing cybersecurity solutions, as enabling DoH might impact DNS traffic filtering tools.\n\n"},"Technologies/HTTPS":{"title":"HTTPS","links":["Technologies/DNS"],"tags":[],"content":"Hypertext Transfer Protocol Secure - HTTPS\nIt is an extension of HTTP that encrypts communication over a computer network, enhancing security and privacy. It uses TLS (Transport Layer Security) or SSL (Secure Sockets Layer) for encryption, protecting against eavesdropping and tampering. HTTPS is essential for securely transmitting sensitive data, such as login credentials and financial transactions, ensuring the authenticity of websites and the privacy of user communications.\nKey Features\n\n\nEncryption: Secures data in transit using TLS/SSL, making it unreadable to interceptors.\n\n\nAuthentication: Verifies the identity of websites and services using digital certificates, ensuring users are communicating with the intended party.\n\n\nProtection: Guards against man-in-the-middle attacks and DNS spoofing, safeguarding user data and privacy.\n\n"},"Technologies/Key-Pair":{"title":"Key Pair","links":[],"tags":[],"content":"A cryptography key pair consists of two related but distinct cryptographic keys:\n\nPrivate Key: A secret key that is used to decrypt, sign, or authenticate data. It’s called “private” because it should be kept confidential and secure to prevent unauthorized access.\nPublic Key: A publicly accessible key that is used to encrypt, verify, or authenticate data. It’s called “public” because it can be shared freely without compromising the security of the system.\n\nHow do key pairs work?\nHere’s a simplified overview of how key pairs are used in various cryptographic scenarios:\nEncryption\n\nAlice wants to send a secure message to Bob.\nBob generates a key pair and shares his public key with Alice.\nAlice uses Bob’s public key to encrypt the message.\nBob uses his private key to decrypt the message.\n\nDigital Signatures\n\nAlice wants to send a document to Bob and prove its authenticity.\nAlice generates a key pair and uses her private key to sign the document.\nBob uses Alice’s public key to verify the signature and ensure the document hasn’t been tampered with.\n\nAuthentication\n\nAlice wants to access a secure system or service.\nThe system generates a key pair and shares its public key with Alice.\nAlice uses the system’s public key to encrypt a challenge or password.\nThe system uses its private key to decrypt the challenge or password and authenticate Alice.\n\nKey Pair Properties\n\nAsymmetric: Key pairs are asymmetric, meaning that the private key is not easily derived from the public key.\nMathematical relationship: The private and public keys are mathematically related, allowing for encryption, decryption, signing, and verification.\nUnique: Each key pair is unique, ensuring that data encrypted with a public key can only be decrypted with the corresponding private key.\n\nTypes of Key Pairs\n\nRSA (Rivest-Shamir-Adleman): A popular algorithm used for encryption, decryption, and digital signatures.\nElliptic Curve Cryptography (ECC): A more modern algorithm used for encryption, decryption, and digital signatures, offering better security with smaller key sizes.\nDiffie-Hellman (DH): A key exchange algorithm used to establish a shared secret key between two parties.\n\nIn summary, cryptography key pairs are a fundamental component of secure online communications, enabling encryption, digital signatures, and authentication. By using a pair of related but distinct keys, key pairs provide a secure way to protect data and ensure its authenticity."},"Technologies/Mainline-DHT":{"title":"Mainline DHT","links":["Technologies/DHT","Concepts/2.Censorship"],"tags":[],"content":"Mainline DHT is a standard Distributed Hash Table (DHT) implementation widely used in the BitTorrent network, based on the Kademlia protocol. This decentralized system allows for efficient data storage and retrieval across a vast network of nodes, making it highly resilient and scalable.\nKey Features\n\nDecentralization: It operates without a central authority, enhancing its resilience against failures and censorship.\nScalability: It can easily scale to accommodate more data and users by adding more nodes to the network.\nEfficiency: By distributing data across multiple nodes, Mainline DHT provides fast access to data without the need for a central server.\n\nApplications\n\nBitTorrent Network: Mainline DHT adds tracker capabilities to each peer in the BitTorrent network, enhancing its resilience and reducing dependency on centralized trackers.\nPeer-to-Peer File Sharing: Beyond BitTorrent, DHTs like Mainline are used for instant messaging, name resolution, and other peer-to-peer file sharing applications.\n"},"Technologies/Paykit":{"title":"Paykit","links":["Pubky-Core/Data-Stores"],"tags":[],"content":"Paykit abstracts and automates any payment method behind a single, static public key. The public key belongs to a Pubky instance and points to a data store containing all supported payment endpoints. Paykit enables applications where users pay directly to profiles, so offers a very intuitive experience, particularly when multiple payment methods are possible within the system."},"index":{"title":"index","links":["Pubky-Core/Introduction","Pubky-Core/Pkarr/Introduction","Pubky-App/Introduction","Pubky-Core/Data-Stores","Concepts/3.Credible-Exit","Concepts/Semantic-Social-Graph"],"tags":[],"content":"Welcome to the Pubky Knowledge Base\nThis is a knowledge base for the Pubky platform, which includes Pubky Core, PKARR and Pubky App. These documents are a work in progress, much like Pubky’s protocols and applications!\nWhat is Pubky?\nPubky attempts to unlock the web by realizing our vision for a key-based, self-regulating web that puts users in control.\nSo far, Pubky does this by combining practical decentralized routing &amp; identity (PKARR), with simple interoperable hosting (Homeservers) that allow for a Credible Exit, and a publishing application that facilitates the creation of a Semantic Social Graph, which can be used for filtering, discovery, matching and coordination.\nGet Started\n\nGetting Started with PKARR - If your main interest is using the most decentralized, key-based identity &amp; routing method, start with PKARR.\nPubky Core - Introduction - If you want run your own Homeserver and apply PKARR, check out Pubky Core.\nPubky App - Introduction - If you want to dig into the application, indexer, etc, start here!\n"},"readme":{"title":"readme","links":[],"tags":[],"content":":brain: Pubky Knowledge Base\nWelcome to the Pubky Knowledge base - we are excited to have you here.\n🔗 Access the Pubky Knowledge Base: notes.pubky,app!\n\nThe current Knowledge base is a mix of reality, dreams, visions, actuality and plans.\n\nThe Knowledge Base is a resource that encompasses our broad vision for Pubky, along with high-level explanations of the architecture for both the Pubky Protocol and the Pubky App, as well as key concepts. Use this as your go-to guide to help you navigate unfamiliar topics and find answers to the most common questions.\n📝 Contributing Knowledge\nWe kindly ask you to help us improve this documentation for a clearer, more accurate and concise knowledge base. Simply open a PR!\n🏗️ Build static Quartz site\nIn order to build the static website from this obsidian vault, ensure that NodeJS is installed on your system.\n\nEnter in the terminal to the project root and access to the /quartz directory (cd quartz)\nInstall dependencies with npm install\nFinally build the site with npm run docs and check it out at localhost:8080\n"}}